{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3fcd46-c757-4a47-9b60-8ef02213d1c0",
   "metadata": {},
   "source": [
    "# MLOps workshop with Amazon SageMaker\n",
    "\n",
    "## Module 03 (**optional**): Automate the whole dataset preparation and model training pipeline using Low-code Experience for SageMaker Pipelines.\n",
    "\n",
    "We're introducing a low-code experience for data scientists to convert the Machine Learning (ML) development code into repeatable and reusable workflow steps of Amazon SageMaker Pipelines.\n",
    "\n",
    "This notebook shows the example of orchestrating jobs for model building and batch inference using low-code experience for SageMaker Pipelines, utilizing `@step` decorator. We build an automated model building pipeline for a house prices prediction, based on the well-known California housing dataset with a simple regression model in Tensorflow 2\n",
    "\n",
    "We will use the same dataset and model inroduced in [Module 02: Transform the data and train a model using SageMaker managed training job](../02_manual_sagemaker_process_train/02_manual_sagemaker_process_train.ipynb) notebook. \n",
    "\n",
    "**Note** this notebook can only run on `Base Python 3.0` Kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c4e37-83c7-4d31-b780-b52a861ed976",
   "metadata": {},
   "source": [
    "## Install the dependencies\n",
    "\n",
    "We will create a `requirements.txt` file that will be used in this notebook, and in the pre-processing, training and evaluation jobs as part of the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c1b42-6c90-4207-9986-a3c6c7be9ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "pandas==2.1.4\n",
    "scikit-learn==1.3.2\n",
    "tensorflow==2.15.0\n",
    "sagemaker>=2.203.0,<3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4c944-dd52-45a0-8743-c7b31db730e9",
   "metadata": {},
   "source": [
    "Now we will install the dependencies on the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020b36f-1208-495a-aac6-b4d1c6b7012e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20abcad7-b373-4ab8-9d21-2e8da37dfb55",
   "metadata": {},
   "source": [
    "## Setup Configuration file path\n",
    "\n",
    "We are setting the directory in which the `config.yaml` file resides so that step decorator can make use of the settings.\n",
    "\n",
    "You can see we use default `ml.m5.large` for the compute to be run with the `@step` decorator. Also, note `requirements.txt` will be installed as default.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f08abd-434f-41dd-b722-2cf40760be5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "SchemaVersion: '1.0'\n",
    "SageMaker:\n",
    "  PythonSDK:\n",
    "    Modules:\n",
    "      RemoteFunction:\n",
    "        # role arn is not required if in SageMaker Notebook instance or SageMaker Studio\n",
    "        # Uncomment the following line and replace with the right execution role if in a local IDE\n",
    "        # RoleArn: <replace the role arn here>\n",
    "        InstanceType: ml.m5.large\n",
    "        Dependencies: ./requirements.txt\n",
    "        IncludeLocalWorkDir: true\n",
    "        CustomFileFilter:\n",
    "          IgnoreNamePatterns: # files or directories to ignore\n",
    "          - \"*.ipynb\" # all notebook files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fce868-f125-4c88-82d9-47baed6d6d33",
   "metadata": {},
   "source": [
    "We can use configuration file `config.yaml` to set default values of the infrastructure such as instance type, and dependencies to run the pipeline. We use environment variable \"SAGEMAKER_USER_CONFIG_OVERRIDE\" to set the path to configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ed1ec-122b-42a8-adba-e01e8a4cbeac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# Set path to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a9ebe-6edc-473e-b355-bc7f2d4550b3",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "First we'll load the California Housing dataset, save the raw feature data and use it in the step as part of the Low-code Experience for SageMaker Pipeline.  We'll also save the labels for training and testing.\n",
    "    \n",
    "More info on the dataset:\n",
    "\n",
    "This dataset was obtained from the StatLib repository. http://lib.stat.cmu.edu/datasets/\n",
    "\n",
    "The target variable is the median house value for California districts.\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca5730-9864-475f-a7bc-927933579c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463ac1b-31a0-4af9-8152-71ae61fdaa88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/california_housing/cal_housing.tgz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43d0b5-a3cd-4ebd-9293-0ee2957f1f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -zxf cal_housing.tgz 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cc0d9-7e73-4869-b93f-609149f89fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "    \"medianHouseValue\",\n",
    "]\n",
    "df = pd.read_csv(\"CaliforniaHousing/cal_housing.data\", names=columns, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31938adf-a229-40fb-80e7-d53eaf4313c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_normalize = [\n",
    "    'medianIncome', 'housingMedianAge', 'totalRooms', \n",
    "    'totalBedrooms', 'population', 'households', 'medianHouseValue'\n",
    "]\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    df[column] = np.log1p(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a96137-29e6-479b-9327-911609739717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(\"medianHouseValue\", axis=1)\n",
    "Y = df[\"medianHouseValue\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d62ddf-361e-473d-9d18-3232d0b438da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Features:\", list(X.columns))\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Dataset Type:\", type(X))\n",
    "print(\"Label set shape:\", Y.shape)\n",
    "print(\"Label set Type:\", type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81532b5a-0085-4907-9eae-adc7a8a59330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We partition the dataset into 2/3 training and 1/3 test set.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67e3e1-0aa8-4e40-a1a2-ee9331fea993",
   "metadata": {},
   "source": [
    "## Define variables and pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91dee7ce-5ed9-4a51-b8f5-838a4ee6e0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = \"tf-2-basic-lyft-and-shift-pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3c5a9-6bea-4321-8c13-16069b908e0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will define a parameterized `instance_type`, so we can override the default `ml.m5.large` defined in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f5e24-d5a8-49f4-b8d9-b9513ca73731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f67b95-bc16-4563-ae6f-d9140d727420",
   "metadata": {},
   "source": [
    "## Preprocessing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae759b-e3c9-4860-8b7a-d6561ac5107b",
   "metadata": {},
   "source": [
    "The pre-processing function uses scikit-learn StandardScaler to scale the features and convert them to NumPy.\n",
    "\n",
    "Note that `keep_alive_period_in_seconds` parameter in @step decorator indicates how many seconds we want to keep the instance alive, waiting to be reused for the next pipeline step execution. Setting this parameter speeds up the pipeline execution because we reduce the launching of new instances to execute pipeline steps. Note also that we override the default 1instance type with the parameter `instance_type` defined in the function parameters.  \n",
    "\n",
    "This step returns the normalized/scaled training and test datasets as `NumPy` arrays to be used in the next training and in evaluation stpes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255bb031-4039-42e3-86e3-012384ab02f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"data-preprocessing\",\n",
    "    instance_type=instance_type,\n",
    "    keep_alive_period_in_seconds=600,\n",
    ")\n",
    "def preprocess(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train.to_numpy())\n",
    "    x_train_transformed_npy = scaler.transform(x_train.to_numpy())\n",
    "    print(f\"x_train_transformed_npy: {x_train_transformed_npy}\")\n",
    "    x_test_transformed_npy = scaler.transform(x_test.to_numpy())\n",
    "    print(f\"x_test_transformed_npy: {x_test_transformed_npy}\")\n",
    "    y_train_transformed_npy = y_train.to_numpy()\n",
    "    print(f\"y_train_transformed_npy: {y_train_transformed_npy}\")\n",
    "    y_test_transformed_npy = y_test.to_numpy() \n",
    "    print(f\"y_test_transformed_npy: {y_test_transformed_npy}\")\n",
    "    \n",
    "    return(x_train_transformed_npy, x_test_transformed_npy, y_train_transformed_npy, y_test_transformed_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa5d21-6e0f-44f5-b05e-d695f279246d",
   "metadata": {},
   "source": [
    "## Training Step\n",
    "\n",
    "We train a TensorFlow model in this training step, using @step-decorated function with the normalized/scaled California housing training and test datasets as `NumPy` arrays. Both training and test datasets are coming from the output of the previous pre-processing step. Note also that we override the default 1instance type with the parameter `instance_type` defined in the function parameters. \n",
    "\n",
    "This step returns the TensorFlow model to be used in the next evaluation step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858e86b-1acf-4029-bf3b-acd45a4859b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "    \n",
    "def get_model():\n",
    "    inputs = tf.keras.Input(shape=(8,))\n",
    "    hidden_1 = tf.keras.layers.Dense(8, activation='tanh')(inputs)\n",
    "    hidden_2 = tf.keras.layers.Dense(4, activation='sigmoid')(hidden_1)\n",
    "    outputs = tf.keras.layers.Dense(1)(hidden_2)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "@step(\n",
    "    name=\"model-training\",\n",
    "    instance_type=instance_type,\n",
    "    keep_alive_period_in_seconds=600,\n",
    ")\n",
    "def train(x_train, x_test, y_train, y_test):      \n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    \n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        device = '/GPU:0'\n",
    "    else:\n",
    "        device = '/CPU:0'\n",
    "    print(f\"will use: {device}\")\n",
    "    \n",
    "    batch_size = 128\n",
    "    epochs = 25\n",
    "    learning_rate = 0.01\n",
    "    print('batch_size = {}, epochs = {}, learning rate = {}'.format(batch_size, epochs, learning_rate))\n",
    "\n",
    "    with tf.device(device):\n",
    "        model = get_model()\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=(x_test, y_test))\n",
    "\n",
    "        # evaluate on test set\n",
    "        scores = model.evaluate(x_test, y_test, batch_size, verbose=2)\n",
    "        print(\"\\nTest MSE :\", scores)\n",
    "        return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32b578-6f21-424d-b323-e46e3a04f42a",
   "metadata": {},
   "source": [
    "## Evaluation Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4dbe9-15bd-49c0-83cc-7196b59f9908",
   "metadata": {},
   "source": [
    "In this step, we create a @step-decorated function evaluate the trained TensorFlow model on the test dataset. Note also that we override the default 1instance type with the parameter `instance_type` defined in the function parameters. \n",
    "\n",
    "This step returns a report dictionary containing the `MSE` score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede6c247-312d-4a41-ba6a-946c75476a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_step_name = \"model-evaluation\"\n",
    "\n",
    "@step(\n",
    "    name=evaluation_step_name,\n",
    "    instance_type=instance_type,\n",
    "    keep_alive_period_in_seconds=600,\n",
    ")\n",
    "def evaluate(model, x_test, y_test):\n",
    "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print(\"\\nTest MSE :\", scores)\n",
    "    report_dict = {\"mse\": str(scores)}\n",
    "    print(f\"report_dict: {report_dict}\")\n",
    "    return(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d491a2a3-9554-4b16-84e9-8c4994017e39",
   "metadata": {},
   "source": [
    "## Putting everything together: creating the Pipeline and running the pipeline execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b554985-f418-4847-806a-16b9dd007a85",
   "metadata": {},
   "source": [
    "We connect all defined pipeline `@step` functions into a multi-step pipeline. Then, we submit and execute the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dde82c-1522-44b1-aa16-957cd38bc6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "step_process_result = preprocess(x_train, x_test, y_train, y_test)\n",
    "step_train_result = train(step_process_result[0], step_process_result[1], step_process_result[2], step_process_result[3])\n",
    "step_evaluation_result = evaluate(step_train_result, step_process_result[1], step_process_result[3]) \n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        instance_type,\n",
    "    ],\n",
    "    steps=[\n",
    "        step_evaluation_result,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b1476-1456-4d4c-acf7-a7ddafc5cb98",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917217d-a18c-41aa-89ec-ff0d47ec1131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0fc27-c175-4015-bf5e-dd17e3f5f8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2c868-1690-46f1-b70c-9982f13a651d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff889c61-27b3-47de-a608-eb08d7a67dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ad539-bf78-4a87-bcf0-eb43ee5d308c",
   "metadata": {},
   "source": [
    "## Getting the result of the evaluation step\n",
    "\n",
    "We will retrieve the output of the evaluation step, which is the report dictionary containing the `MSE` score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047c200-816b-482e-8a0b-243491653fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report_dict = execution.result(step_name=evaluation_step_name)\n",
    "print(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a40be-695a-41c0-be54-cc8361a30689",
   "metadata": {},
   "source": [
    "## Clean up Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bd14b-677e-42fe-8bd8-b4f9806e0f1c",
   "metadata": {},
   "source": [
    "### Delete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526a5c2-242f-4970-b3ff-ee316bbc24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060365a4-7d47-4941-bf83-7034dc8af5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
